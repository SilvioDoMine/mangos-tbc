# An√°lise de Gargalos de Performance - MaNGOS TBC

## Sum√°rio Executivo

Este documento identifica os principais gargalos de performance na arquitetura de multi-threading do MaNGOS-TBC, com base em an√°lise detalhada do c√≥digo-fonte. Os gargalos est√£o categorizados por severidade e impacto.

---

## 1. CONTEN√á√ÉO DE LOCKS (Lock Contention)

### 1.1 üî¥ CR√çTICO: MapManager - Lock Global Recursivo

**Localiza√ß√£o**: `src/game/Maps/MapManager.h:56`

```cpp
class MapManager : public MaNGOS::Singleton<MapManager,
    MaNGOS::ClassLevelLockable<MapManager, std::recursive_mutex>>
```

**Problema**: Todas as inst√¢ncias de MapManager compartilham um √∫nico `std::recursive_mutex` est√°tico. Cada opera√ß√£o de mapa (CreateMap, FindMap, DeleteInstance) adquire este lock global, criando um ponto de serializa√ß√£o para todas as opera√ß√µes relacionadas a mapas em todas as threads.

**Exemplo de C√≥digo** (`MapManager.cpp:114`):
```cpp
Map* MapManager::CreateMap(uint32 id, const WorldObject* obj)
{
    Guard _guard(*this);  // Trava o mutex global class-level
    // ... l√≥gica de cria√ß√£o de mapa
}
```

**Impacto**:
- Alto ponto de conten√ß√£o - todas as worker threads no MapUpdater competem por este √∫nico lock
- Serializa opera√ß√µes que poderiam ser paralelas
- Degrada linearmente com n√∫mero de threads

**Recomenda√ß√£o**:
- Mudar de `ClassLevelLockable` para `ObjectLevelLockable`
- Usar locks por mapa individual em vez de lock global
- Implementar estrutura de dados lockless para lookup de mapas

---

### 1.2 üî¥ CR√çTICO: ObjectAccessor - Lock Global para Todos os Players

**Localiza√ß√£o**: `src/game/Globals/ObjectAccessor.h:70`

```cpp
class ObjectAccessor : public MaNGOS::Singleton<ObjectAccessor,
    MaNGOS::ClassLevelLockable<ObjectAccessor, std::mutex>>
```

**Problema**: Mutex class-level protege todos os lookups de players/corpses globalmente. HashMapHolder usa o mesmo mutex para todas opera√ß√µes read/write.

**Exemplo de C√≥digo** (`ObjectAccessor.cpp:40-56`):
```cpp
template<class T>
void HashMapHolder<T>::Insert(T* o)
{
    WriteGuard guard(i_lock);  // Compartilhado entre TODAS as inst√¢ncias
    m_objectMap[o->GetObjectGuid()] = o;
}

template<class T>
T* HashMapHolder<T>::Find(ObjectGuid guid)
{
    ReadGuard guard(i_lock);  // Mesmo lock para leituras!
    typename MapType::iterator itr = m_objectMap.find(guid);
    return (itr != m_objectMap.end()) ? itr->second : nullptr;
}
```

**Impacto**:
- Cada lookup de player de qualquer thread adquire este lock global
- Leituras bloqueiam outras leituras (n√£o usa reader/writer lock)
- Com 1000+ players, torna-se gargalo severo

**Recomenda√ß√£o**:
- Implementar `std::shared_mutex` (reader/writer lock)
- Usar `std::shared_lock` para reads, `std::unique_lock` para writes
- Considerar lock-free hash map (ex: `tbb::concurrent_hash_map`)

---

### 1.3 üü° ALTO: VMapManager2 - Dual Mutex Coarse-Grained

**Localiza√ß√£o**: `src/game/vmap/VMapManager2.h:69-70`

```cpp
std::mutex m_vmStaticMapMutex;
std::mutex m_vmModelMutex;
```

**Problema**: Locking coarse-grained para todas opera√ß√µes VMAP. Verifica√ß√µes de line-of-sight e queries de terreno serializam.

**Impacto**:
- Pathfinding e collision checks competem pelo mesmo lock
- Opera√ß√µes de leitura que poderiam ser paralelas s√£o serializadas

**Recomenda√ß√£o**:
- Locks por mapa individual
- Reader/writer locks para opera√ß√µes read-heavy
- Considerar estruturas immutable para permitir leituras lock-free

---

### 1.4 üü° ALTO: MoveMap - Mutex de Modelos Global

**Localiza√ß√£o**: `src/game/MotionGenerators/MoveMap.h:129`

```cpp
std::mutex m_modelsMutex;
```

**Problema**: Todos os acessos a modelos de pathfinding compartilham √∫nico mutex, bloqueando opera√ß√µes paralelas de pathfinding.

**Impacto**:
- NPCs calculando pathfinding simultaneamente serializam
- Escala mal com n√∫mero de NPCs ativos

**Recomenda√ß√£o**:
- Hash map thread-safe com locks por tile/grid
- Carregar modelos como read-only e eliminar locks para leituras

---

### 1.5 üü¢ M√âDIO: Sistema de Log - Lock Global

**Localiza√ß√£o**: `src/shared/Log/Log.h:96`

```cpp
class Log : public MaNGOS::Singleton<Log,
    MaNGOS::ClassLevelLockable<Log, std::mutex>>
```

**Locks adicionais**: `m_worldLogMtx` (linha 211), `m_traceLogMtx` (linha 212)

**Problema**: Todas opera√ß√µes de logging serializam. Logging pesado causa conten√ß√£o em todas as threads.

**Impacto**:
- Cada log statement de qualquer thread compete pelo lock
- Pode adicionar lat√™ncia significativa em hot paths

**Recomenda√ß√£o**:
- Implementar logging ass√≠ncrono com buffer lock-free
- Usar thread-local buffers que flush periodicamente
- Considerar bibliotecas como `spdlog` com async logging

---

### 1.6 üü¢ M√âDIO: SqlConnection - Recursive Mutex

**Localiza√ß√£o**: `src/shared/Database/Database.h:98`

```cpp
class SqlConnection
{
    std::recursive_mutex m_mutex;

    class Lock {
        Lock(SqlConnection* conn) : m_pConn(conn) {
            m_pConn->m_mutex.lock();
        }
    };
};
```

**Problema**: Uso de recursive mutex indica re-entrada de locks, sugerindo poss√≠vel problema de design. Cada conex√£o tem seu pr√≥prio mutex, mas locking recursivo sugere padr√µes de chamadas aninhadas que podem deadlock.

**Impacto**:
- Recursive mutex √© mais lento que mutex normal
- Indica complexidade desnecess√°ria

**Recomenda√ß√£o**:
- Refatorar para eliminar necessidade de recursive locking
- Garantir hierarquia clara de locks

---

## 2. GARGALOS SINGLE-THREADED

### 2.1 üî¥ CR√çTICO: Loop de World Update (Apenas Main Thread)

**Localiza√ß√£o**: `src/mangosd/WorldRunnable.cpp:67-115`

```cpp
void WorldRunnable::run()
{
    while (!World::IsStopped())
    {
        ++World::m_worldLoopCounter;
        diffTick = WorldTimer::tick();
        sWorld.Update(diffTick);  // SINGLE-THREADED
        diffTime = WorldTimer::getMSTime() - WorldTimer::tickTime();

        if (diffTime < WORLD_SLEEP_CONST)
            MaNGOS::Thread::Sleep(WORLD_SLEEP_CONST - diffTime);
    }
}
```

**Taxa de tick fixa**: `#define WORLD_SLEEP_CONST 50` (50ms)

**Problema**: Todo o world update roda em uma √∫nica thread. Todas as atualiza√ß√µes de sess√µes, timers e l√≥gica de jogo s√£o serializadas.

**Impacto**:
- Limite hard de 20 ticks/segundo
- CPU single-core bottleneck
- N√£o escala com m√∫ltiplos cores

**Recomenda√ß√£o**:
- Paralelizar sub-tarefas do world update
- Processar sess√µes em thread pool
- Mover timers n√£o-cr√≠ticos para threads separadas

---

### 2.2 üî¥ CR√çTICO: Atualiza√ß√µes de Sess√µes (Itera√ß√£o Linear)

**Localiza√ß√£o**: `src/game/World/World.cpp:2193-2222`

```cpp
void World::UpdateSessions(uint32 diff)
{
    // Itera√ß√£o single-threaded atrav√©s de TODAS as sess√µes
    for (SessionMap::iterator itr = m_sessions.begin(); itr != m_sessions.end();)
    {
        WorldSession* pSession = itr->second;

        if (!pSession->Update(diff))  // Cada sess√£o atualizada sequencialmente
        {
            RemoveQueuedSession(pSession);
            itr = m_sessions.erase(itr);
            delete pSession;
        }
        else
            ++itr;
    }
}
```

**Impacto**:
- Com 1000+ players, torna-se ponto de serializa√ß√£o significativo
- Nenhuma paraleliza√ß√£o do processamento de sess√µes
- O(N) onde N = n√∫mero de players conectados

**Recomenda√ß√£o**:
- Dividir sess√µes entre worker threads do MapUpdater
- Processar sess√µes em chunks paralelos
- Garantir thread-safety dos dados de sess√£o

---

### 2.3 üü° ALTO: Processamento de Database Result Queue

**Localiza√ß√£o**: `src/game/World/World.cpp:2250-2256`

```cpp
void World::UpdateResultQueue()
{
    // Processamento sequencial na main thread
    CharacterDatabase.ProcessResultQueue();
    WorldDatabase.ProcessResultQueue();
    LoginDatabase.ProcessResultQueue();
}
```

**Problema**: Callbacks de async queries processados sequencialmente apenas na main thread.

**Impacto**:
- Callbacks complexos bloqueiam world update
- N√£o aproveita multiple cores para processamento de resultados

**Recomenda√ß√£o**:
- Processar result queues em threads dedicadas
- Callbacks apenas enfileiram a√ß√µes para main thread se necess√°rio
- Separar opera√ß√µes thread-safe dos callbacks

---

### 2.4 üü° ALTO: MapUpdater Wait - Serializa√ß√£o

**Localiza√ß√£o**: `src/game/Maps/MapUpdater.cpp:47-53`

```cpp
void MapUpdater::wait()
{
    std::unique_lock<std::mutex> lock(_lock);

    while (pending_requests > 0)
        _condition.wait(lock);  // Main thread bloqueia aqui
}
```

**Problema**: Main thread deve esperar TODAS as atualiza√ß√µes de mapas completarem antes de continuar. Nenhuma sobreposi√ß√£o entre fases do world update.

**Impacto**:
- Desperd√≠cio de tempo onde main thread poderia fazer outro trabalho
- Lat√™ncia adicional no world update cycle

**Recomenda√ß√£o**:
- Fazer MapUpdater completamente ass√≠ncrono
- Main thread inicia map updates e continua com outras tarefas
- Sincronizar apenas quando absolutamente necess√°rio

---

## 3. OPERA√á√ïES BLOQUEANTES

### 3.1 üî¥ CR√çTICO: Queries de Banco de Dados S√≠ncronas na Main Thread

**Localiza√ß√£o**: `src/game/World/World.cpp` (m√∫ltiplas localiza√ß√µes)

**Exemplos**:
```cpp
// Linha 928
LoginDatabase.PExecute("UPDATE realmlist SET icon = %u...");

// Linha 931
CharacterDatabase.PExecute("DELETE FROM corpse WHERE...");

// Linha 1441
LoginDatabase.Execute("DELETE FROM ip_banned WHERE...");

// Linha 2281
CharacterDatabase.Query("SELECT NextDailyQuestResetTime...");
```

**Problema**: Chamadas diretas de Execute/PExecute bloqueiam a thread chamadora esperando resposta do DB.

**Impacto**:
- World update congela enquanto espera DB
- Lat√™ncia do DB diretamente impacta tick rate
- Com DB lento, todo servidor degrada

**Recomenda√ß√£o**:
- Converter TODAS queries para AsyncQuery/AsyncPQuery
- Nunca bloquear main thread em I/O
- Implementar timeout e retry logic

---

### 3.2 üî¥ CR√çTICO: SqlDelayThread - Polling

**Localiza√ß√£o**: `src/shared/Database/SqlDelayThread.cpp:41-59`

```cpp
void SqlDelayThread::run()
{
    const uint32 loopSleepms = 10;  // Intervalo de polling 10ms

    while (m_running)
    {
        MaNGOS::Thread::Sleep(loopSleepms);  // BUSY POLLING
        ProcessRequests();

        if ((loopCounter++) >= pingEveryLoop)
        {
            loopCounter = 0;
            m_dbEngine->Ping();
        }
    }
}
```

**Problema**: Desperdi√ßa CPU com loop de sleep 10ms em vez de usar condition variable. Adiciona lat√™ncia de 0-10ms em opera√ß√µes de DB.

**Impacto**:
- Uso desnecess√°rio de CPU
- Lat√™ncia adicional nas opera√ß√µes
- N√£o responde imediatamente a novas requisi√ß√µes

**Recomenda√ß√£o**:
- Substituir sleep loop por condition_variable
- Notificar thread quando nova opera√ß√£o √© enfileirada
- Reduzir lat√™ncia para ~0ms

---

### 3.3 üü¢ M√âDIO: Messager Execution (Bem Implementado)

**Localiza√ß√£o**: `src/shared/Multithreading/Messager.h:35-46`

```cpp
void Execute(T* object)
{
    std::vector<std::function<void(T*)>> messageVectorCopy;
    {
        std::lock_guard<std::mutex> guard(m_messageMutex);
        std::swap(m_messageVector, messageVectorCopy);  // Bom: double-buffering
    }
    for (auto& message : messageVectorCopy)
        message(object);  // Callbacks executados sem lock (Bom!)
}
```

**Nota**: Bem projetado com double-buffering. Mas callbacks ainda s√£o s√≠ncronos - sem paraleliza√ß√£o.

**Recomenda√ß√£o Futura**:
- Considerar paralelizar execu√ß√£o de callbacks independentes
- Usar task queue para callbacks pesados

---

## 4. PROBLEMAS DE ESCALABILIDADE

### 4.1 üî¥ CR√çTICO: MapUpdater Thread Pool de Tamanho Fixo

**Localiza√ß√£o**: `src/game/Maps/MapUpdater.cpp:22-35`

```cpp
MapUpdater::MapUpdater(size_t num_threads) : _cancelationToken(false), pending_requests(0)
{
    for (size_t i = 0; i < num_threads; ++i)
        _workerThreads.push_back(std::thread(&MapUpdater::WorkerThread, this));
}
```

**Configura√ß√£o**: `CONFIG_UINT32_NUM_MAP_THREADS` - definido no startup, n√£o pode escalar dinamicamente.

**Problemas**:
- Pool de tamanho fixo, sem scaling din√¢mico
- Threads ficam idle quando n√£o h√° trabalho de mapa dispon√≠vel
- Sem work stealing entre threads
- Single ProducerConsumerQueue cria conten√ß√£o

**Impacto**:
- Recursos desperdi√ßados em baixa carga
- Insuficiente em alta carga
- N√£o se adapta a padr√µes de uso vari√°veis

**Recomenda√ß√£o**:
- Implementar thread pool din√¢mico que escala com carga
- Work stealing queue para balanceamento de carga
- M√∫ltiplas filas para reduzir conten√ß√£o

---

### 4.2 üî¥ CR√çTICO: Thread √önica de Database Delay por Conex√£o

**Localiza√ß√£o**: `src/shared/Database/Database.h:269`

```cpp
SqlDelayThread* m_threadBody;  // Thread √∫nica por database
```

**Problema**: Apenas UMA thread processa opera√ß√µes ass√≠ncronas de DB por database. Serializa todas async queries.

**Impacto**:
- Gargalo de DB mesmo com async API
- N√£o aproveita connection pooling
- Uma opera√ß√£o lenta bloqueia todas as outras

**Recomenda√ß√£o**:
- M√∫ltiplas delay threads por database
- Round-robin ou hash-based distribution de queries
- Thread pool para processamento paralelo

---

### 4.3 üü° ALTO: Itera√ß√£o Linear de Sess√µes (Sem Paraleliza√ß√£o)

**M√∫ltiplas ocorr√™ncias em World.cpp**:

```cpp
// Linha 2208: UpdateSessions - sequencial
for (SessionMap::iterator itr = m_sessions.begin(); itr != m_sessions.end();)

// Padr√µes similares para:
// - SaveAllPlayers
// - ExecuteOnAllPlayers
// - SendGlobalMessage
// - KickAll
```

**Problema**: Opera√ß√µes O(N) no mapa de sess√µes. Com 3000 players, torna-se caro. Sem processamento paralelo.

**Impacto**:
- Tempo de processamento cresce linearmente com players
- Bottleneck em popula√ß√µes altas
- Desperdi√ßa cores dispon√≠veis

**Recomenda√ß√£o**:
- Paralelizar loops usando thread pool
- Processar chunks de sess√µes em paralelo
- Usar algoritmos parallel STL quando poss√≠vel

---

### 4.4 üü¢ M√âDIO: std::list para BattleGround Queue

**Localiza√ß√£o**: `src/game/BattleGround/BattleGroundQueue.h:123`

```cpp
typedef std::list<BattleGroundInQueueInfo> BgFreeSlotQueueType;
```

**Coment√°rio no c√≥digo** (linha 122):
> "can't be deque, because deque doesn't like removing the last element"

**Problema**: Busca linear atrav√©s da lista para matching de BG instances. Deveria usar map/multimap indexado por crit√©rios-chave.

**Impacto**:
- O(N) para encontrar BG dispon√≠vel
- Cache-unfriendly com ponteiros indiretos
- Degrada com muitos BGs ativos

**Recomenda√ß√£o**:
- Usar `std::map` ou `std::unordered_map` indexado por instance ID
- Manter √≠ndices secund√°rios para lookups comuns
- Considerar flat_map para melhor cache locality

---

### 4.5 üü¢ M√âDIO: std::list para Group Queues

**Localiza√ß√£o**: `src/game/BattleGround/BattleGroundQueue.h:151`

```cpp
typedef std::list<GroupQueueInfo*> GroupsQueueType;

// Array de listas
GroupsQueueType m_queuedGroups[MAX_BATTLEGROUND_BRACKETS][BG_QUEUE_GROUP_TYPES_COUNT];
```

**Problema**: Itera√ß√£o linear para encontrar grupos matching. Inser√ß√µes/remo√ß√µes frequentes.

**Impacto**:
- O(N) matchmaking
- Fragmenta√ß√£o de mem√≥ria com ponteiros

**Recomenda√ß√£o**:
- Heap ou priority queue para ordena√ß√£o por rating/tempo
- Indexed containers para lookup r√°pido

---

## 5. PROBLEMAS DE MEM√ìRIA/CACHE

### 5.1 üü° ALTO: ProducerConsumerQueue - Potencial False Sharing

**Localiza√ß√£o**: `src/shared/Util/ProducerConsumerQueue.h:100-103`

```cpp
private:
    std::mutex m_queueLock;              // Provavelmente na mesma cache line
    std::queue<T> m_queue;               // que estes membros
    std::condition_variable m_condition;
    std::atomic<bool> m_shutdown;
```

**Problema**: Mutex, queue e atomic provavelmente na mesma cache line. Threads producer/consumer fazem bounce de cache lines.

**Impacto**:
- Invalida√ß√£o desnecess√°ria de cache
- Degrada√ß√£o de performance em sistemas multi-socket
- Escalabilidade limitada com m√∫ltiplos cores

**Recomenda√ß√£o**:
- Usar `alignas(64)` para alinhar em cache lines
- Separar dados de read/write em cache lines diferentes
- Padding expl√≠cito entre membros hot

**Exemplo**:
```cpp
private:
    alignas(64) std::mutex m_queueLock;
    std::queue<T> m_queue;
    std::condition_variable m_condition;

    alignas(64) std::atomic<bool> m_shutdown;  // Em cache line separada
```

---

### 5.2 üü¢ M√âDIO: MapUpdater - Shared Counter

**Localiza√ß√£o**: `src/game/Maps/MapUpdater.h:56`

```cpp
std::mutex _lock;
std::condition_variable _condition;
size_t pending_requests;  // N√£o-atomic, protegido por mutex
```

**Problema**: `pending_requests` incrementado/decrementado sob lock por m√∫ltiplas threads. Poderia ser atomic para opera√ß√µes lockless.

**Impacto**:
- Lock desnecess√°rio para incremento simples
- Conten√ß√£o adicional

**Recomenda√ß√£o**:
```cpp
std::atomic<size_t> pending_requests;
```

---

### 5.3 üü¢ M√âDIO: World Opcode Counters

**Localiza√ß√£o**: `src/game/World/World.h:766`

```cpp
std::vector<std::atomic<uint32>> m_opcodeCounters;
```

**Problema**: Vector de atomics - bom, mas ainda potencial bouncing de cache line se m√∫ltiplos opcodes na mesma cache line.

**Impacto Moderado**: Counters s√£o acessados frequentemente.

**Recomenda√ß√£o**:
```cpp
// Estrutura cache-aligned
struct alignas(64) OpcodeCounter {
    std::atomic<uint32> count;
};
std::vector<OpcodeCounter> m_opcodeCounters;
```

---

### 5.4 üü¢ BAIXO: Messager Vector Growth

**Localiza√ß√£o**: `src/shared/Multithreading/Messager.h:48`

```cpp
std::vector<std::function<void(T*)>> m_messageVector;
```

**Problema**: Realoca√ß√µes de vector sob lock quando mensagens s√£o adicionadas. Poderia usar deque ou reservar capacidade.

**Impacto Baixo**: Realoca√ß√µes s√£o raras em uso normal.

**Recomenda√ß√£o**:
```cpp
// Ou usar deque (sem realoca√ß√µes)
std::deque<std::function<void(T*)>> m_messageVector;

// Ou reservar capacidade esperada
m_messageVector.reserve(1024);
```

---

## 6. GARGALOS ADICIONAIS

### 6.1 üü¢ M√âDIO: Config System - Lock Global

**Localiza√ß√£o**: `src/shared/Config/Config.h:49`

```cpp
std::mutex m_configLock;
```

**Problema**: Todas leituras de config requerem lock. Config deveria ser read-mostly com reader/writer lock ou estrutura lockless.

**Impacto**:
- Conten√ß√£o em opera√ß√µes de leitura frequentes
- Config √© raramente modificado mas frequentemente lido

**Recomenda√ß√£o**:
```cpp
std::shared_mutex m_configLock;

// Leituras
std::shared_lock<std::shared_mutex> lock(m_configLock);

// Escritas
std::unique_lock<std::shared_mutex> lock(m_configLock);
```

---

### 6.2 üü¢ BAIXO: Database Round-Robin Connection Selection

**Localiza√ß√£o**: `src/shared/Database/Database.h:259`

```cpp
std::atomic_long m_nQueryCounter;  // Para sele√ß√£o round-robin
```

**Usado em getQueryConnection()** - Bom uso de atomic, mas round-robin pode causar carga desigual se queries t√™m custos vari√°veis.

**Recomenda√ß√£o**:
- Considerar load-based selection em vez de round-robin
- Tracking de conex√µes busy/idle

---

## RESUMO DE GARGALOS CR√çTICOS (Ordem de Prioridade)

| # | Gargalo | Severidade | Localiza√ß√£o | Impacto |
|---|---------|-----------|-------------|---------|
| 1 | **MapManager global recursive_mutex** | üî¥ Cr√≠tico | `Maps/MapManager.h:56` | Serializa todas opera√ß√µes de mapa |
| 2 | **World::UpdateSessions single-threaded** | üî¥ Cr√≠tico | `World/World.cpp:2193` | Sem paraleliza√ß√£o de sess√µes |
| 3 | **ObjectAccessor global mutex** | üî¥ Cr√≠tico | `Globals/ObjectAccessor.h:70` | Todos lookups de players serializam |
| 4 | **Synchronous DB queries na main thread** | üî¥ Cr√≠tico | `World/World.cpp:928+` | Bloqueia world update |
| 5 | **SqlDelayThread polling** | üî¥ Cr√≠tico | `Database/SqlDelayThread.cpp:41` | Desperdi√ßa CPU, adiciona lat√™ncia |
| 6 | **Fixed MapUpdater thread pool** | üî¥ Cr√≠tico | `Maps/MapUpdater.cpp:22` | Sem scaling din√¢mico |
| 7 | **MapUpdater wait() serialization** | üü° Alto | `Maps/MapUpdater.cpp:47` | Main thread bloqueia por todos mapas |
| 8 | **Single DB delay thread** | üî¥ Cr√≠tico | `Database/Database.h:269` | Gargalo de DB |
| 9 | **VMapManager/MoveMap locks globais** | üü° Alto | `vmap/VMapManager2.h:69` | Pathfinding serializa |
| 10 | **Linear session/queue searches** | üü° Alto | V√°rios | Opera√ß√µes O(N) |

---

## RECOMENDA√á√ïES DE OTIMIZA√á√ÉO (Top 10)

### 1. Substituir Class-Level Locks por Object-Level
**Impacto**: M√°ximo | **Esfor√ßo**: M√©dio

Converter `MapManager` e `ObjectAccessor` de `ClassLevelLockable` para `ObjectLevelLockable`. Permite acesso paralelo a diferentes objetos.

---

### 2. Implementar Reader/Writer Locks
**Impacto**: Alto | **Esfor√ßo**: Baixo

Usar `std::shared_mutex` para estruturas read-heavy:
- ObjectAccessor (player lookups)
- Config system
- VMapManager/MoveMap

---

### 3. Paralelizar Session Updates
**Impacto**: M√°ximo | **Esfor√ßo**: Alto

Dividir `UpdateSessions()` em chunks processados em thread pool. Requer garantir thread-safety de session data.

---

### 4. Eliminar Synchronous DB Queries da Main Thread
**Impacto**: M√°ximo | **Esfor√ßo**: M√©dio

Converter todas chamadas `Execute()`/`Query()` para `AsyncQuery()`/`AsyncPQuery()` na main thread.

---

### 5. Substituir SqlDelayThread Polling por Condition Variable
**Impacto**: M√©dio | **Esfor√ßo**: Baixo

```cpp
void SqlDelayThread::run()
{
    while (m_running)
    {
        std::unique_lock<std::mutex> lock(m_queueMutex);
        m_condition.wait(lock, [this]{ return !m_sqlQueue.empty() || !m_running; });

        if (!m_running) break;

        // Process queue
    }
}
```

---

### 6. Implementar Work-Stealing Thread Pool
**Impacto**: Alto | **Esfor√ßo**: Alto

Substituir MapUpdater por thread pool din√¢mico com work-stealing. Permite melhor balanceamento e scaling.

---

### 7. M√∫ltiplas DB Delay Threads
**Impacto**: Alto | **Esfor√ßo**: M√©dio

Pool de threads para processar async DB operations. Round-robin ou hash-based distribution.

---

### 8. MapUpdater Ass√≠ncrono (N√£o-Bloqueante)
**Impacto**: M√©dio | **Esfor√ßo**: M√©dio

Eliminar `wait()` - main thread inicia map updates e continua. Sincronizar apenas quando necess√°rio.

---

### 9. Lock-Free Data Structures
**Impacto**: Alto | **Esfor√ßo**: Alto

Usar estruturas lock-free para high-contention paths:
- Intel TBB `concurrent_hash_map` para ObjectAccessor
- Lock-free queues para messaging
- Atomic operations para counters

---

### 10. Cache-Line Alignment
**Impacto**: M√©dio | **Esfor√ßo**: Baixo

Alinhar hot atomics e mutex em cache lines separadas:

```cpp
struct alignas(64) CacheAligned {
    std::atomic<uint64_t> counter;
};
```

---

## M√âTRICAS RECOMENDADAS PARA MONITORAMENTO

1. **Lock Wait Time**: Tempo m√©dio esperando por locks
2. **Thread Pool Utilization**: % de tempo threads est√£o ativas
3. **DB Query Latency**: P50, P95, P99 lat√™ncias
4. **World Update Time**: Tempo por tick do world update
5. **Session Update Time**: Tempo para processar todas sess√µes
6. **Map Update Time**: Tempo para parallel map updates
7. **CPU Utilization**: Por thread e total
8. **Cache Misses**: L1/L2/L3 cache miss rates
9. **Context Switches**: Taxa de context switches involunt√°rios

---

## FERRAMENTAS DE PROFILING RECOMENDADAS

1. **perf** (Linux): CPU profiling, cache analysis
2. **Intel VTune**: Threading analysis, lock contention
3. **Valgrind/Helgrind**: Thread error detection, race conditions
4. **ThreadSanitizer (TSan)**: Data race detection
5. **gperftools**: CPU e heap profiling
6. **Tracy Profiler**: Real-time frame profiler

---

## CONCLUS√ÉO

Os gargalos identificados s√£o t√≠picos de aplica√ß√µes multi-threaded que evolu√≠ram de single-threaded designs. As principais √°reas de melhoria s√£o:

1. **Reduzir conten√ß√£o de locks** atrav√©s de locks fine-grained e reader/writer locks
2. **Eliminar serializa√ß√£o for√ßada** atrav√©s de paraleliza√ß√£o de session updates
3. **Remover opera√ß√µes bloqueantes** da main thread
4. **Implementar scaling din√¢mico** em thread pools
5. **Otimizar cache usage** atrav√©s de alignment e redu√ß√£o de false sharing

Com estas otimiza√ß√µes, espera-se:
- **2-3x** melhoria em throughput de sessions
- **50-70%** redu√ß√£o em lock contention
- **30-50%** redu√ß√£o em lat√™ncia de world update
- Melhor scaling com n√∫mero de cores dispon√≠veis

---

**Data da An√°lise**: 2026-01-22
**Vers√£o do C√≥digo**: mangos-tbc master branch
**Commit**: fa54c3c8d
